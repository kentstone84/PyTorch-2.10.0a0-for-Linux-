# ========================================================================
# PyTorch 2.10.0a0 + Triton 3.5.0 Runtime Image
# RTX 50-series (SM 12.0 Blackwell) Optimization Stack
# ========================================================================
FROM nvidia/cuda:13.0.1-runtime-ubuntu24.04

ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

# -------------------------------------------------------------------------
# Install Runtime Dependencies
# -------------------------------------------------------------------------
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 \
    python3-pip \
    python3-dev \
    build-essential \
    ca-certificates \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /workspace

# -------------------------------------------------------------------------
# Copy Requirements and Wheels
# -------------------------------------------------------------------------
COPY requirements.txt /workspace/
COPY triton_sm120.whl /workspace/
COPY torch_sm120.whl /workspace/

# -------------------------------------------------------------------------
# Install Python Dependencies
# -------------------------------------------------------------------------
RUN pip install --no-cache-dir -r requirements.txt

# -------------------------------------------------------------------------
# Install Triton + PyTorch with SM 12.0 Support
# -------------------------------------------------------------------------
RUN echo "Installing Triton with Blackwell support..." && \
    pip install --no-cache-dir triton_sm120.whl && \
    echo "Installing PyTorch 2.10.0a0 with SM 12.0 support..." && \
    pip install --no-cache-dir torch_sm120.whl --force-reinstall

# -------------------------------------------------------------------------
# Verify Installation
# -------------------------------------------------------------------------
RUN python3 -c "import torch; import triton; \
    print('='*70); \
    print('RTX 5080 Optimization Stack - Installation Verified'); \
    print('='*70); \
    print(f'PyTorch Version: {torch.__version__}'); \
    print(f'Triton Version: {triton.__version__}'); \
    print(f'CUDA Available: {torch.cuda.is_available()}'); \
    print(f'CUDA Version: {torch.version.cuda if torch.cuda.is_available() else \"N/A\"}'); \
    print('='*70)"

# -------------------------------------------------------------------------
# Environment Configuration
# -------------------------------------------------------------------------
ENV TORCH_CUDA_ARCH_LIST="12.0"
ENV CUDA_VISIBLE_DEVICES=0

# Enable optimizations
ENV TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
ENV CUDA_MODULE_LOADING=LAZY

WORKDIR /workspace

CMD ["python3"]
